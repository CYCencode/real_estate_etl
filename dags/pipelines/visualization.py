# v2
#pipelines/visualization.py
"""è¦–è¦ºåŒ–åœ–è¡¨ç”Ÿæˆæ¨¡çµ„"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.patches import Patch
import contextily as cx
from pyproj import Transformer
from io import BytesIO, StringIO

from config import (
    COLORS, ZONE_ORDER, BUILDING_TYPE_ORDER, CITY_BOUNDS, MAX_POINTS,
    REPORT_CITIES, CITY_DISPLAY_TO_CODE,
    FIGURE_SIZE_WIDE, FIGURE_SIZE_MEDIUM, FIGURE_SIZE_LARGE, FIGURE_SIZE_MAP, SUBPLOT_LEFT, SUBPLOT_RIGHT,
    LEGEND_RIGHT, LEGEND_RIGHT_LOWER, CHART_DPI, LABEL_THRESHOLD,
    PRICE_COLORS, SIZE_MAPPING,
    AGE_BINS, AGE_LABELS, AREA_BINS, AREA_LABELS,
    PRICE_BINS_USED, PRICE_LABELS_USED, PRICE_BINS_NEW, PRICE_LABELS_NEW
)
from utils import log_to_gcs, upload_chart_to_gcs, check_charts_exist, load_existing_charts

# ==================== å…±ç”¨è¼”åŠ©å‡½æ•¸ ====================
def create_dual_axis_figure():
    """å‰µå»ºå·¦å³é›™å­åœ–çš„ Figure"""
    fig = plt.figure(figsize=FIGURE_SIZE_WIDE)
    ax1 = fig.add_axes(SUBPLOT_LEFT)
    ax2 = fig.add_axes(SUBPLOT_RIGHT)
    return fig, ax1, ax2

def setup_stacked_bar_axis(ax, title, is_left=True):
    """è¨­å®šå †ç–Šæ©«æ¢åœ–çš„è»¸å±¬æ€§"""
    ax.set_xlabel('ç™¾åˆ†æ¯” (%)', fontsize=12)
    ax.set_ylabel('å€åŸŸ' if is_left else '', fontsize=12)
    ax.set_title(title, fontsize=13, pad=10, weight='bold')
    ax.set_xlim(0, 100)
    ax.grid(axis='x', alpha=0.3, linestyle='--')
    ax.invert_yaxis()
    if not is_left:
        ax.set_yticklabels([])

def add_percentage_labels(ax, threshold=LABEL_THRESHOLD):
    """ç‚ºå †ç–Šæ©«æ¢åœ–æ·»åŠ ç™¾åˆ†æ¯”æ¨™ç±¤"""
    for container in ax.containers:
        labels = [f'{value:.0f}%' if value >= threshold else '' 
                 for value in container.datavalues]
        ax.bar_label(container, labels=labels, label_type='center', fontsize=9, weight='bold')

def add_dual_legends(fig, labels_left, labels_right, title_left, title_right):
    """æ·»åŠ å·¦å³å…©å€‹åœ–ä¾‹"""
    legend_ax1 = fig.add_axes(LEGEND_RIGHT)
    legend_ax1.axis('off')
    handles_left = [plt.Rectangle((0,0),1,1, fc=COLORS[i]) 
                   for i in range(len(labels_left))]
    legend_ax1.legend(handles_left, labels_left, loc='upper center', title=title_left, frameon=True, fontsize=9, title_fontsize=10)
    
    legend_ax2 = fig.add_axes(LEGEND_RIGHT_LOWER)
    legend_ax2.axis('off')
    handles_right = [plt.Rectangle((0,0),1,1, fc=COLORS[i]) 
                    for i in range(len(labels_right))]
    legend_ax2.legend(handles_right, labels_right, loc='upper center', title=title_right, frameon=True, fontsize=9, title_fontsize=10)


def save_and_upload(chart_name, year, season):
    """å„²å­˜ä¸¦ä¸Šå‚³åœ–è¡¨ï¼ˆåŠ å…¥è§£æåº¦è¿½è¹¤ï¼‰"""
    buffer = BytesIO()
    
    # å–å¾—ç•¶å‰ figure
    fig = plt.gcf()
    
    # âœ… åŸ‹é» 1: è¨˜éŒ„ Figure å°ºå¯¸ï¼ˆè‹±å‹ï¼‰
    fig_width, fig_height = fig.get_size_inches()
    log_to_gcs('INFO', f"ğŸ“Š [{chart_name}] Figure å°ºå¯¸: {fig_width:.2f}\" x {fig_height:.2f}\" (DPI={CHART_DPI})")
    
    # âœ… åŸ‹é» 2: è¨ˆç®—å¯¦éš›åƒç´ å°ºå¯¸
    pixel_width = int(fig_width * CHART_DPI)
    pixel_height = int(fig_height * CHART_DPI)
    log_to_gcs('INFO', f"ğŸ“Š [{chart_name}] é æœŸåƒç´ : {pixel_width} x {pixel_height} px")
    
    # å„²å­˜åœ–è¡¨åˆ° buffer
    plt.savefig(buffer, format='png', dpi=CHART_DPI, bbox_inches='tight')
    plt.close()
    
    # âœ… åŸ‹é» 3: è¨˜éŒ„ buffer å¤§å°ï¼ˆå„²å­˜å¾Œï¼‰
    buffer_size_kb = buffer.getbuffer().nbytes / 1024
    log_to_gcs('INFO', f"ğŸ“Š [{chart_name}] Buffer å¤§å°: {buffer_size_kb:.2f} KB")
    
    # âœ… åŸ‹é» 4: ä½¿ç”¨ PIL é©—è­‰å¯¦éš›åœ–ç‰‡è§£æåº¦
    try:
        from PIL import Image
        buffer.seek(0)
        img = Image.open(buffer)
        actual_width, actual_height = img.size
        img_format = img.format
        img_mode = img.mode
        
        log_to_gcs('INFO', f"ğŸ“Š [{chart_name}] PIL é©—è­‰ - å¯¦éš›è§£æåº¦: {actual_width} x {actual_height} px")
        log_to_gcs('INFO', f"ğŸ“Š [{chart_name}] PIL é©—è­‰ - æ ¼å¼: {img_format}, æ¨¡å¼: {img_mode}")
        
        # æª¢æŸ¥è§£æåº¦æ˜¯å¦ç¬¦åˆé æœŸ
        if actual_width != pixel_width or actual_height != pixel_height:
            log_to_gcs('WARNING', f"âš ï¸ [{chart_name}] è§£æåº¦ä¸ç¬¦ï¼é æœŸ {pixel_width}x{pixel_height}, å¯¦éš› {actual_width}x{actual_height}")
        else:
            log_to_gcs('INFO', f"âœ… [{chart_name}] è§£æåº¦ç¬¦åˆé æœŸ")
            
    except Exception as e:
        log_to_gcs('ERROR', f"âŒ [{chart_name}] PIL é©—è­‰å¤±æ•—: {str(e)}")
    
    # ä¸Šå‚³åˆ° GCS
    buffer.seek(0)  # é‡ç½® buffer ä½ç½®
    result_url = upload_chart_to_gcs(buffer, chart_name, year, season, compress=False)
    
    # âœ… åŸ‹é» 5: è¨˜éŒ„ä¸Šå‚³çµæœ
    log_to_gcs('INFO', f"ğŸ“Š [{chart_name}] ä¸Šå‚³å®Œæˆï¼ŒURL é•·åº¦: {len(result_url)} å­—å…ƒ")
    
    return result_url


def create_stacked_bar_plot(df, bins, labels, category_name='category'):
    """é€šç”¨çš„å †ç–Šæ©«æ¢åœ–è³‡æ–™è™•ç†"""
    df_copy = df.copy()
    df_copy[category_name] = pd.cut(df_copy['value'], bins=bins, labels=labels)
    pivot = pd.crosstab(df_copy['city_display'], df_copy[category_name],  normalize='index') * 100
    return pivot.reindex([zone for zone in ZONE_ORDER if zone in pivot.index])
    
# ==================== åœ–è¡¨ç”Ÿæˆå‡½æ•¸ï¼ˆAirflow DAG ä½¿ç”¨ï¼‰====================
def create_stacked_bar_charts(**context):
    """ç”Ÿæˆå››ç¨®å †ç–Šæ©«æ¢åœ–ï¼šç¸½åƒ¹ã€å»ºåªã€å»ºç‰©é¡å‹ã€å±‹é½¡ï¼ˆAirflow ç‰ˆæœ¬ï¼‰"""
    log_to_gcs('INFO', "é–‹å§‹ç”Ÿæˆå †ç–Šæ©«æ¢åœ–...")
    
    ti = context['task_instance']
    df_used_json = ti.xcom_pull(task_ids='load_data', key='df_used')
    df_new_json = ti.xcom_pull(task_ids='load_data', key='df_new')
    year = ti.xcom_pull(task_ids='load_data', key='year')
    season = ti.xcom_pull(task_ids='load_data', key='season')
    
    df_used = pd.read_json(StringIO(df_used_json), orient='split')
    df_new = pd.read_json(StringIO(df_new_json), orient='split')
    
    # æª¢æŸ¥åœ–è¡¨æ˜¯å¦å·²å­˜åœ¨
    check_result = check_charts_exist(year, season)
    
    if check_result['exists']:
        log_to_gcs('INFO', f"åœ–è¡¨å·²å­˜åœ¨ï¼Œè·³éç”Ÿæˆï¼Œç›´æ¥è¼‰å…¥: {check_result['folder']}")
        # è¼‰å…¥ç¾æœ‰åœ–è¡¨
        chart_urls = {}
        for chart_type in ['total_price', 'building_area', 'building_type', 'building_age']:
            chart_name = f"{chart_type}_stacked"
            if chart_name in check_result['charts']:
                from utils import get_chart_url_from_gcs
                chart_urls[chart_type] = get_chart_url_from_gcs(year, season, chart_name)
        
        ti.xcom_push(key='stacked_charts', value=chart_urls)
        return chart_urls
    
    # ç”Ÿæˆæ–°åœ–è¡¨
    chart_urls = {}
    
    # 1. ç¸½åƒ¹åˆ†ç´šå †ç–Šåœ–
    if not df_used.empty and not df_new.empty:
        chart_urls['total_price'] = _plot_total_price_distribution(df_used, df_new, year, season)
        chart_urls['building_area'] = _plot_building_area_distribution(df_used, df_new, year, season)
        chart_urls['building_type'] = _plot_building_type_distribution(df_used, df_new, year, season)
    
    # 2. å±‹é½¡åˆ†ç´šå †ç–Šåœ–ï¼ˆåƒ…ä¸­å¤å±‹ï¼‰
    if not df_used.empty:
        chart_urls['building_age'] = _plot_building_age_distribution(df_used, year, season)
    
    ti.xcom_push(key='stacked_charts', value=chart_urls)
    log_to_gcs('INFO', "æ‰€æœ‰å †ç–Šæ©«æ¢åœ–å·²å®Œæˆ")
    return chart_urls

def _plot_total_price_distribution(df_used, df_new, year, season):
    """ç¹ªè£½ç¸½åƒ¹åˆ†ç´šå †ç–Šåœ–"""
    log_to_gcs('INFO', "ç¹ªè£½ç¸½åƒ¹åˆ†ç´šå †ç–Šåœ–...")
    
    # è™•ç†è³‡æ–™
    df_used_copy = df_used.copy()
    df_new_copy = df_new.copy()
    
    df_used_copy['price_range'] = pd.cut(df_used_copy['total_price'], bins=PRICE_BINS_USED, labels=PRICE_LABELS_USED)
    df_new_copy['price_range'] = pd.cut(df_new_copy['total_price'], bins=PRICE_BINS_NEW, labels=PRICE_LABELS_NEW)
    
    pivot_used = pd.crosstab(df_used_copy['city_display'],  df_used_copy['price_range'], normalize='index') * 100
    pivot_new = pd.crosstab(df_new_copy['city_display'],  df_new_copy['price_range'], normalize='index') * 100
    
    pivot_used = pivot_used.reindex([z for z in ZONE_ORDER if z in pivot_used.index])
    pivot_new = pivot_new.reindex([z for z in ZONE_ORDER if z in pivot_new.index])
    
    # ç¹ªè£½åœ–è¡¨
    fig, ax1, ax2 = create_dual_axis_figure()
    
    # å·¦å´ - ä¸­å¤å±‹
    pivot_used.plot(kind='barh', stacked=True, ax=ax1, 
                   color=COLORS[:len(pivot_used.columns)], 
                   width=0.7, legend=False)
    setup_stacked_bar_axis(ax1, 'ä¸­å¤å±‹ - ç¸½åƒ¹æ¯”ä¾‹åˆ†å¸ƒ', is_left=True)
    add_percentage_labels(ax1)
    
    # å³å´ - æ–°æˆå±‹
    pivot_new.plot(kind='barh', stacked=True, ax=ax2, 
                  color=COLORS[:len(pivot_new.columns)], 
                  width=0.7, legend=False)
    setup_stacked_bar_axis(ax2, 'æ–°æˆå±‹ - ç¸½åƒ¹æ¯”ä¾‹åˆ†å¸ƒ', is_left=False)
    add_percentage_labels(ax2)
    
    # æ·»åŠ åœ–ä¾‹
    add_dual_legends(fig, PRICE_LABELS_USED, PRICE_LABELS_NEW,
                    'ä¸­å¤å±‹åƒ¹æ ¼å€é–“', 'æ–°æˆå±‹åƒ¹æ ¼å€é–“')
    
    return save_and_upload('total_price_stacked', year, season)
    
def _plot_building_area_distribution(df_used, df_new, year, season):
    """ç¹ªè£½å»ºåªåˆ†ç´šå †ç–Šåœ–"""
    log_to_gcs('INFO', "ç¹ªè£½å»ºåªåˆ†ç´šå †ç–Šåœ–...")
    
    df_used_copy = df_used.copy()
    df_new_copy = df_new.copy()
    
    # è½‰æ›ç‚ºåªæ•¸
    df_used_copy['area_range'] = pd.cut(
        df_used_copy['building_total_sqm']/3.30579, 
        bins=AREA_BINS, labels=AREA_LABELS
    )
    df_new_copy['area_range'] = pd.cut(
        df_new_copy['building_total_sqm']/3.30579, 
        bins=AREA_BINS, labels=AREA_LABELS
    )
    
    pivot_used = pd.crosstab(df_used_copy['city_display'], df_used_copy['area_range'], normalize='index') * 100
    pivot_new = pd.crosstab(df_new_copy['city_display'], df_new_copy['area_range'], normalize='index') * 100
    
    pivot_used = pivot_used.reindex([z for z in ZONE_ORDER if z in pivot_used.index])
    pivot_new = pivot_new.reindex([z for z in ZONE_ORDER if z in pivot_new.index])
    
    # ç¹ªè£½åœ–è¡¨
    fig, ax1, ax2 = create_dual_axis_figure()
    
    pivot_used.plot(kind='barh', stacked=True, ax=ax1, color=COLORS[:len(AREA_LABELS)], width=0.7, legend=False)
    setup_stacked_bar_axis(ax1, 'ä¸­å¤å±‹ - å»ºåªæ¯”ä¾‹åˆ†å¸ƒ', is_left=True)
    add_percentage_labels(ax1)
    
    pivot_new.plot(kind='barh', stacked=True, ax=ax2, color=COLORS[:len(AREA_LABELS)], width=0.7, legend=False)
    setup_stacked_bar_axis(ax2, 'æ–°æˆå±‹ - å»ºåªæ¯”ä¾‹åˆ†å¸ƒ', is_left=False)
    add_percentage_labels(ax2)
    
    # å–®ä¸€åœ–ä¾‹ï¼ˆå»ºåªç´šè·ç›¸åŒï¼‰
    legend_ax = fig.add_axes(LEGEND_RIGHT)
    legend_ax.axis('off')
    handles = [plt.Rectangle((0,0),1,1, fc=COLORS[i]) 
              for i in range(len(AREA_LABELS))]
    legend_ax.legend(handles, AREA_LABELS, loc='center', title='å»ºåªç´šè·',frameon=True, fontsize=10, title_fontsize=11)
    
    return save_and_upload('building_area_stacked', year, season)
    
def _plot_building_type_distribution(df_used, df_new, year, season):
    """ç¹ªè£½å»ºç‰©é¡å‹å †ç–Šåœ–"""
    log_to_gcs('INFO', "ç¹ªè£½å»ºç‰©é¡å‹å †ç–Šåœ–...")
    
    pivot_used = pd.crosstab(df_used['city_display'], df_used['building_type'], normalize='index') * 100
    pivot_new = pd.crosstab(df_new['city_display'], df_new['building_type'], normalize='index') * 100
    
    all_types = [bt for bt in BUILDING_TYPE_ORDER 
                if bt in pivot_used.columns or bt in pivot_new.columns]
    
    pivot_used = pivot_used.reindex(columns=all_types, fill_value=0)
    pivot_new = pivot_new.reindex(columns=all_types, fill_value=0)
    pivot_used = pivot_used.reindex([z for z in ZONE_ORDER if z in pivot_used.index])
    pivot_new = pivot_new.reindex([z for z in ZONE_ORDER if z in pivot_new.index])
    
    # ç¹ªè£½åœ–è¡¨
    fig, ax1, ax2 = create_dual_axis_figure()
    
    pivot_used.plot(kind='barh', stacked=True, ax=ax1, color=COLORS[:len(pivot_used.columns)], width=0.7, legend=False)
    setup_stacked_bar_axis(ax1, 'ä¸­å¤å±‹ - å»ºç‰©é¡å‹æ¯”ä¾‹åˆ†å¸ƒ', is_left=True)
    add_percentage_labels(ax1)
    
    pivot_new.plot(kind='barh', stacked=True, ax=ax2, color=COLORS[:len(pivot_new.columns)], width=0.7, legend=False)
    setup_stacked_bar_axis(ax2, 'æ–°æˆå±‹ - å»ºç‰©é¡å‹æ¯”ä¾‹åˆ†å¸ƒ', is_left=False)
    add_percentage_labels(ax2)
    
    # å–®ä¸€åœ–ä¾‹
    legend_ax = fig.add_axes(LEGEND_RIGHT)
    legend_ax.axis('off')
    handles = [plt.Rectangle((0,0),1,1, fc=COLORS[i]) 
              for i, _ in enumerate(all_types) if i < len(COLORS)]
    legend_ax.legend(handles, all_types, loc='center', title='å»ºç‰©é¡å‹',frameon=True, fontsize=10, title_fontsize=11)
    
    return save_and_upload('building_type_stacked', year, season)

def _plot_building_age_distribution(df_used, year, season):
    """ç¹ªè£½å±‹é½¡åˆ†ç´šå †ç–Šåœ–ï¼ˆåƒ…ä¸­å¤å±‹ï¼‰"""
    log_to_gcs('INFO', "ç¹ªè£½å±‹é½¡åˆ†ç´šå †ç–Šåœ–...")
    
    df_used_copy = df_used.copy()
    df_used_copy['building_age'] = df_used_copy['transaction_year'] - df_used_copy['build_year']
    df_used_copy['age_range'] = pd.cut(df_used_copy['building_age'], bins=AGE_BINS, labels=AGE_LABELS)
    
    pivot = pd.crosstab(df_used_copy['city_display'], df_used_copy['age_range'], normalize='index') * 100
    pivot = pivot.reindex([z for z in ZONE_ORDER if z in pivot.index])
    
    fig = plt.figure(figsize=FIGURE_SIZE_MEDIUM)
    ax = fig.add_axes([0.15, 0.15, 0.65, 0.75])
    
    pivot.plot(kind='barh', stacked=True, ax=ax, color=COLORS[:len(AGE_LABELS)], width=0.7, legend=False)
    
    ax.set_xlabel('ç™¾åˆ†æ¯” (%)', fontsize=12)
    ax.set_ylabel('å€åŸŸ', fontsize=12)
    ax.set_title('ä¸­å¤å±‹ - å±‹é½¡æ¯”ä¾‹åˆ†å¸ƒ', fontsize=14, pad=10, weight='bold')
    ax.set_xlim(0, 100)
    ax.grid(axis='x', alpha=0.3, linestyle='--')
    ax.invert_yaxis()
    
    add_percentage_labels(ax)
    
    legend_ax = fig.add_axes([0.82, 0.35, 0.08, 0.35])
    legend_ax.axis('off')
    handles = [plt.Rectangle((0,0),1,1, fc=COLORS[i]) 
              for i in range(len(AGE_LABELS))]
    legend_ax.legend(handles, AGE_LABELS, loc='center', title='å±‹é½¡ç´šè·',frameon=True, fontsize=10, title_fontsize=11)
    
    return save_and_upload('building_age_stacked', year, season)

def create_summary_section(**context):
    """ç”Ÿæˆçµ±è¨ˆæ‘˜è¦å€å¡Šï¼ˆåŒ…å«è¡¨æ ¼å’Œæˆäº¤ä»¶æ•¸å †ç–Šåœ–ï¼‰"""
    log_to_gcs('INFO', "ç”Ÿæˆçµ±è¨ˆæ‘˜è¦å€å¡Š...")
    
    ti = context['task_instance']
    
    df_used_json = ti.xcom_pull(task_ids='load_data', key='df_used')
    df_new_json = ti.xcom_pull(task_ids='load_data', key='df_new')
    year = ti.xcom_pull(task_ids='load_data', key='year')
    season = ti.xcom_pull(task_ids='load_data', key='season')
    
    df_used = pd.read_json(StringIO(df_used_json), orient='split')
    df_new = pd.read_json(StringIO(df_new_json), orient='split')
    
    # æª¢æŸ¥åœ–è¡¨æ˜¯å¦å·²å­˜åœ¨
    check_result = check_charts_exist(year, season)
    chart_name = 'transaction_count_stacked'
    
    if chart_name in check_result['charts']:
        log_to_gcs('INFO', f"æˆäº¤ä»¶æ•¸åœ–å·²å­˜åœ¨ï¼Œç›´æ¥è¼‰å…¥")
        from utils import get_chart_url_from_gcs
        transaction_count_url = get_chart_url_from_gcs(year, season, chart_name)
    else:
        # ç”Ÿæˆæˆäº¤ä»¶æ•¸å †ç–Šæ©«æ¢åœ–
        log_to_gcs('INFO', "ç”Ÿæˆæˆäº¤ä»¶æ•¸å †ç–Šæ©«æ¢åœ–...")
        transaction_count_url = _generate_transaction_count_chart(df_used, df_new, year, season)
    
    # ç”Ÿæˆçµ±è¨ˆè¡¨æ ¼ HTML
    summary_data = []
    
    if not df_used.empty and 'city_display' in df_used.columns:
        for city in df_used['city_display'].unique():
            city_data = df_used[df_used['city_display'] == city]
            summary_data.append({
                'city': city,
                'type': 'ä¸­å¤å±‹',
                'count': len(city_data),
                'avg_total_price': city_data['total_price'].mean() / 10000 if 'total_price' in city_data.columns else 0
            })
    
    if not df_new.empty and 'city_display' in df_new.columns:
        for city in df_new['city_display'].unique():
            city_data = df_new[df_new['city_display'] == city]
            summary_data.append({
                'city': city,
                'type': 'æ–°æˆå±‹',
                'count': len(city_data),
                'avg_total_price': city_data['total_price'].mean() / 10000 if 'total_price' in city_data.columns else 0
            })
    
    summary_df = pd.DataFrame(summary_data)
    
    html = '<table style="width: 100%; border-collapse: collapse; margin: 20px 0; font-size: 14px;">'
    html += '<thead><tr style="background-color: #F3F4F6;">'
    html += '<th style="border: 1px solid #D1D5DB; padding: 8px; color: #000000;">ç¸£å¸‚</th>'
    html += '<th style="border: 1px solid #D1D5DB; padding: 8px; color: #000000;">é¡å‹</th>'
    html += '<th style="border: 1px solid #D1D5DB; padding: 8px; color: #000000;">æˆäº¤ä»¶æ•¸</th>'
    html += '<th style="border: 1px solid #D1D5DB; padding: 8px; color: #000000;">å¹³å‡ç¸½åƒ¹(è¬)</th>'
    html += '</tr></thead><tbody>'
    
    for _, row in summary_df.iterrows():
        html += f'<tr><td style="border: 1px solid #D1D5DB; padding: 8px; color: #000000;">{row["city"]}</td>'
        html += f'<td style="border: 1px solid #D1D5DB; padding: 8px; color: #000000;">{row["type"]}</td>'
        html += f'<td style="border: 1px solid #D1D5DB; padding: 8px; text-align: right; color: #000000;">{row["count"]:,}</td>'
        html += f'<td style="border: 1px solid #D1D5DB; padding: 8px; text-align: right; color: #000000;">{row["avg_total_price"]:.1f}</td></tr>'
    
    html += '</tbody></table>'
    
    ti.xcom_push(key='transaction_count_url', value=transaction_count_url)
    ti.xcom_push(key='summary_table_html', value=html)
    
    log_to_gcs('INFO', "çµ±è¨ˆæ‘˜è¦å€å¡Šç”Ÿæˆå®Œæˆ")
    return {'table': html, 'chart_url': transaction_count_url}

def _generate_transaction_count_chart(df_used, df_new, year, season):
    """ç”Ÿæˆæˆäº¤ä»¶æ•¸åœ–"""
    used_counts = []
    new_counts = []
    
    for city in ZONE_ORDER:
        if city == 'æ–°ç«¹å¸‚/ç«¹åŒ—å¸‚':
            used_count = len(df_used[df_used['city_display'] == city]) if not df_used.empty else 0
            new_count = len(df_new[df_new['city_display'] == city]) if not df_new.empty else 0
        else:
            used_count = len(df_used[df_used['city'] == city]) if not df_used.empty else 0
            new_count = len(df_new[df_new['city'] == city]) if not df_new.empty else 0
        
        used_counts.append(used_count)
        new_counts.append(new_count)
    
    fig, ax = plt.subplots(figsize=(12, 8))
    y_pos = range(len(ZONE_ORDER))
    
    ax.barh(y_pos, used_counts, label='ä¸­å¤å±‹', color='#3B82F6', alpha=0.8)
    ax.barh(y_pos, new_counts, left=used_counts, label='æ–°æˆå±‹', color='#F59E0B', alpha=0.8)
    
    for i, (used, new) in enumerate(zip(used_counts, new_counts)):
        if used > 0:
            ax.text(used/2, i, f'{used:,}', ha='center', va='center', fontsize=10, weight='bold')
        if new > 0:
            ax.text(used + new/2, i, f'{new:,}', ha='center', va='center', fontsize=10, weight='bold')
        
        total = used + new
        if total > 0:
            ax.text(total + max(used_counts + new_counts) * 0.02, i, 
                   f'ç¸½è¨ˆ: {total:,}', ha='left', va='center', fontsize=9)
    
    ax.set_yticks(y_pos)
    ax.set_yticklabels(ZONE_ORDER)
    ax.set_xlabel('æˆäº¤ä»¶æ•¸', fontsize=12, weight='bold')
    ax.set_title('å„ç¸£å¸‚ä¸­å¤å±‹/æ–°æˆå±‹æˆäº¤ä»¶æ•¸åˆ†å¸ƒ', fontsize=14, pad=20, weight='bold')
    ax.legend(loc='lower right', fontsize=11)
    ax.grid(axis='x', alpha=0.3, linestyle='--')
    
    plt.tight_layout()
    
    buffer = BytesIO()
    plt.savefig(buffer, format='png', dpi=CHART_DPI, bbox_inches='tight')
    plt.close()
    
    return upload_chart_to_gcs(buffer, 'transaction_count_stacked', year, season, compress=False)

def create_city_boxplots_combined(**context):
    """ç‚ºæ¯å€‹ç¸£å¸‚å»ºç«‹ä¸¦æ’ç®±å‹åœ–"""
    log_to_gcs('INFO', "ç”Ÿæˆç®±å‹åœ–...")
    
    ti = context['task_instance']
    
    df_used_json = ti.xcom_pull(task_ids='load_data', key='df_used')
    df_new_json = ti.xcom_pull(task_ids='load_data', key='df_new')
    year = ti.xcom_pull(task_ids='load_data', key='year')
    season = ti.xcom_pull(task_ids='load_data', key='season')
    
    df_used = pd.read_json(StringIO(df_used_json), orient='split')
    df_new = pd.read_json(StringIO(df_new_json), orient='split')
    
    # æª¢æŸ¥åœ–è¡¨æ˜¯å¦å·²å­˜åœ¨
    check_result = check_charts_exist(year, season)
    
    # æª¢æŸ¥æ˜¯å¦æ‰€æœ‰ç®±å‹åœ–éƒ½å­˜åœ¨
    required_boxplot_charts = [f"boxplot_{CITY_DISPLAY_TO_CODE[city]}_combined" 
                               for city, _ in REPORT_CITIES]
    all_boxplots_exist = all(chart in check_result['charts'] for chart in required_boxplot_charts)
    
    if all_boxplots_exist:
        log_to_gcs('INFO', "æ‰€æœ‰ç®±å‹åœ–å·²å­˜åœ¨ï¼Œç›´æ¥è¼‰å…¥")
        boxplot_urls = []
        from utils import get_chart_url_from_gcs
        
        for display_name, _ in REPORT_CITIES:
            chart_name = f"boxplot_{CITY_DISPLAY_TO_CODE[display_name]}_combined"
            url = get_chart_url_from_gcs(year, season, chart_name)
            boxplot_urls.append({
                'city': display_name,
                'url': url
            })
        
        ti.xcom_push(key='boxplot_urls', value=boxplot_urls)
        return boxplot_urls
    
    # ç”Ÿæˆæ–°åœ–è¡¨
    city_groups = {}
    
    for display_name, city_name in REPORT_CITIES:
        zones_used = df_used.loc[df_used['city'] == city_name, 'zip_zone'].unique().tolist() if not df_used.empty else []
        zones_new = df_new.loc[df_new['city'] == city_name, 'zip_zone'].unique().tolist() if not df_new.empty else []
        city_groups[display_name] = list(set(zones_used + zones_new))
    
    boxplot_urls = []
    
    for city_name, zones in city_groups.items():
        city_df_used = df_used[df_used['zip_zone'].isin(zones)].copy() if not df_used.empty else pd.DataFrame()
        city_df_new = df_new[df_new['zip_zone'].isin(zones)].copy() if not df_new.empty else pd.DataFrame()
        
        if len(city_df_used) == 0 and len(city_df_new) == 0:
            log_to_gcs('INFO', f"{city_name} ç„¡è³‡æ–™ï¼Œè·³é")
            continue
        
        zone_counts_used = city_df_used['zip_zone'].value_counts() if not city_df_used.empty else pd.Series()
        zone_counts_new = city_df_new['zip_zone'].value_counts() if not city_df_new.empty else pd.Series()
        
        sorted_zones = sorted(zones, 
                            key=lambda x: (zone_counts_new.get(x, 0), zone_counts_used.get(x, 0)), 
                            reverse=True)
        
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=FIGURE_SIZE_LARGE)
        
        def plot_boxplot(ax, city_df, sorted_zones, zone_counts, title_suffix):
            available_zones = [zone for zone in sorted_zones if zone in zone_counts.index]
            
            if len(available_zones) == 0:
                ax.text(0.5, 0.5, 'ç„¡è³‡æ–™', ha='center', va='center', 
                       fontsize=20, transform=ax.transAxes)
                ax.set_title(f'{city_name}{title_suffix} æˆ¿åƒ¹åˆ†å¸ƒèˆ‡æˆäº¤é‡',
                           fontsize=16, pad=20, weight='bold')
                return
            
            city_df['zip_zone'] = pd.Categorical(city_df['zip_zone'],
                                                 categories=available_zones,
                                                 ordered=True)
            
            positions = range(len(available_zones))
            bp = ax.boxplot(
                [city_df[city_df['zip_zone'] == zone]['total_price'].values
                 for zone in available_zones],
                positions=positions,
                widths=0.6,
                patch_artist=True,
                showfliers=False,
                medianprops=dict(color='red', linewidth=2),
                boxprops=dict(facecolor='lightblue', alpha=0.7),
                whiskerprops=dict(linewidth=1.5),
                capprops=dict(linewidth=1.5)
            )
            
            ax.set_xticks(positions)
            ax.set_xticklabels(available_zones, rotation=45, ha='right')
            
            y_min_current, y_max_current = ax.get_ylim()
            
            all_min_values = []
            for zone in available_zones:
                zone_data = city_df[city_df['zip_zone'] == zone]['total_price'].values
                if len(zone_data) > 0:
                    all_min_values.append(zone_data.min())
            
            if all_min_values:
                global_min = min(all_min_values)
                y_range = y_max_current - y_min_current
                label_space = y_range * 0.08
                new_y_min = min(global_min - label_space, y_min_current)
                ax.set_ylim(new_y_min, y_max_current)
                
                for i, zone in enumerate(available_zones):
                    count = zone_counts[zone]
                    zone_data = city_df[city_df['zip_zone'] == zone]['total_price'].values
                    if len(zone_data) > 0:
                        zone_min = zone_data.min()
                        y_pos = (zone_min + new_y_min) / 2
                        
                        ax.text(i, y_pos, f'n={count}',
                               ha='center', va='center', fontsize=9,
                               bbox=dict(boxstyle='round,pad=0.3',
                                       facecolor='yellow', alpha=0.5))
            
            ax.yaxis.set_major_formatter(
                plt.FuncFormatter(lambda x, p: f'{int(x/10000)}è¬'))
            
            ax.set_xlabel('å€åŸŸ', fontsize=12, weight='bold')
            ax.set_ylabel('ç¸½åƒ¹ (è¬å…ƒ)', fontsize=12, weight='bold')
            ax.set_title(f'{city_name}{title_suffix} æˆ¿åƒ¹åˆ†å¸ƒèˆ‡æˆäº¤é‡',
                        fontsize=16, pad=20, weight='bold')
            
            ax.grid(axis='y', alpha=0.3, linestyle='--')
            
            total_transactions = len(city_df[city_df['zip_zone'].isin(available_zones)])
            median_price = city_df[city_df['zip_zone'].isin(available_zones)]['total_price'].median()
            mean_price = city_df[city_df['zip_zone'].isin(available_zones)]['total_price'].mean()
            
            stats_text = (f'ç¸½æˆäº¤æ•¸: {total_transactions:,}ç­†\n'
                         f'ä¸­ä½æ•¸: {median_price/10000:.0f}è¬\n'
                         f'å¹³å‡æ•¸: {mean_price/10000:.0f}è¬')
            
            ax.text(0.02, 0.98, stats_text, transform=ax.transAxes,
                   fontsize=10, verticalalignment='top',
                   bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
        
        plot_boxplot(ax1, city_df_used, sorted_zones, zone_counts_used, 'ä¸­å¤å±‹')
        plot_boxplot(ax2, city_df_new, sorted_zones, zone_counts_new, 'æ–°æˆå±‹')
        
        plt.tight_layout()
        
        buffer = BytesIO()
        plt.savefig(buffer, format='png', dpi=CHART_DPI, bbox_inches='tight')
        plt.close()
        
        chart_url = upload_chart_to_gcs(buffer, f'boxplot_{CITY_DISPLAY_TO_CODE[city_name]}_combined', year, season, compress=False)
        boxplot_urls.append({
            'city': city_name,
            'url': chart_url
        })
        
        log_to_gcs('INFO', f"{city_name} ä¸¦æ’ç®±å‹åœ–å·²å®Œæˆ")
    
    ti.xcom_push(key='boxplot_urls', value=boxplot_urls)
    
    log_to_gcs('INFO', "æ‰€æœ‰ä¸¦æ’ç®±å‹åœ–å·²å®Œæˆ")
    return boxplot_urls

def convert_to_web_mercator(df):
    """å°‡ WGS84 è½‰æ›ç‚º Web Mercator"""
    transformer = Transformer.from_crs("EPSG:4326", "EPSG:3857", always_xy=True)
    x, y = transformer.transform(df['longitude'].values, df['latitude'].values)
    df = df.copy()
    df['x'] = x
    df['y'] = y
    return df


def classify_price_quantile(df, price_col='total_price'):
    """ä¾æ“šç¸½åƒ¹å››åˆ†ä½è·åˆ†é¡"""
    price_q1 = df[price_col].quantile(0.25)
    price_q2 = df[price_col].quantile(0.50)
    price_q3 = df[price_col].quantile(0.75)
    price_max = df[price_col].max()
    price_min = df[price_col].min()
    
    def classify(price):
        if pd.isna(price):
            return 'æœªçŸ¥', 0
        if price <= price_q1:
            return f'{price_min/10000:,.0f}~{price_q1/10000:,.0f}è¬', 1
        elif price <= price_q2:
            return f'{price_q1/10000:,.0f}~{price_q2/10000:,.0f}è¬', 2
        elif price <= price_q3:
            return f'{price_q2/10000:,.0f}~{price_q3/10000:,.0f}è¬', 3
        else:
            return f'{price_q3/10000:,.0f}~{price_max/10000:,.0f}è¬', 4
    
    result = df[price_col].apply(lambda x: pd.Series(classify(x)))
    result.columns = ['price_category', 'price_order']
    
    return result, (price_min, price_q1, price_q2, price_q3, price_max)


def classify_size_quantile(df, size_col='building_total_sqm'):
    """ä¾æ“šåªæ•¸å››åˆ†ä½è·åˆ†é¡"""
    size_q1 = df[size_col].quantile(0.25)
    size_q2 = df[size_col].quantile(0.50)
    size_q3 = df[size_col].quantile(0.75)
    size_max = df[size_col].max()
    size_min = df[size_col].min()
    
    def classify(sqm):
        if pd.isna(sqm):
            return 'æœªçŸ¥', 0
        if sqm <= size_q1:
            return f'{size_min:.1f}~{size_q1:.1f}åª', 1
        elif sqm <= size_q2:
            return f'{size_q1:.1f}~{size_q2:.1f}åª', 2
        elif sqm <= size_q3:
            return f'{size_q2:.1f}~{size_q3:.1f}åª', 3
        else:
            return f'{size_q3:.1f}~{size_max:.1f}åª', 4
    
    result = df[size_col].apply(lambda x: pd.Series(classify(x)))
    result.columns = ['size_category', 'size_order']
    
    return result, (size_min, size_q1, size_q2, size_q3, size_max)


def create_city_scatter_map(df_city, city_name, property_type, year, season):
    """å»ºç«‹å–®ä¸€ç¸£å¸‚çš„æ•£é»åœ–"""
    
    if len(df_city) == 0:
        log_to_gcs('WARNING', f"{city_name} {property_type} æ²’æœ‰è³‡æ–™")
        return None
    
    log_to_gcs('INFO', f"è™•ç† {city_name} {property_type} {len(df_city)} ç­†è³‡æ–™...")
    
    # éæ¿¾ç•°å¸¸åº§æ¨™
    if city_name in CITY_BOUNDS:
        bounds = CITY_BOUNDS[city_name]
        original_len = len(df_city)
        
        df_city = df_city[
            (df_city['latitude'] >= bounds['lat'][0]) &
            (df_city['latitude'] <= bounds['lat'][1]) &
            (df_city['longitude'] >= bounds['lon'][0]) &
            (df_city['longitude'] <= bounds['lon'][1])
        ].copy()
        
        filtered_count = original_len - len(df_city)
        if filtered_count > 0:
            log_to_gcs('INFO', f"éæ¿¾ {filtered_count} ç­†ç•°å¸¸åº§æ¨™ ({filtered_count/original_len*100:.1f}%)")
    
    if len(df_city) == 0:
        log_to_gcs('WARNING', f"{city_name} {property_type} éæ¿¾å¾Œç„¡è³‡æ–™")
        return None

    # è¨˜éŒ„åŸå§‹è³‡æ–™ç­†æ•¸ï¼ˆç”¨æ–¼æ¨™é¡Œè¨»è¨˜ï¼‰
    original_data_count = len(df_city)
    is_sampled = False
    
    # å¦‚æœè³‡æ–™é‡å¤ªå¤§ï¼Œé€²è¡Œæ¡æ¨£
    if len(df_city) > MAX_POINTS:
        log_to_gcs('INFO', f"è³‡æ–™é‡ {len(df_city)} è¶…é {MAX_POINTS}ï¼Œé€²è¡Œæ¡æ¨£...")
        df_city = df_city.sample(n=MAX_POINTS, random_state=42)
        is_sampled = True

    # åº§æ¨™è½‰æ›
    df_city = convert_to_web_mercator(df_city.copy())
    
    # ç¸½åƒ¹åˆ†é¡
    price_result, price_stats = classify_price_quantile(df_city)
    df_city[['price_category', 'price_order']] = price_result
    
    # åªæ•¸åˆ†é¡
    size_result, size_stats = classify_size_quantile(df_city)
    df_city[['size_category', 'size_order']] = size_result
    
    log_to_gcs('INFO', f"{city_name} {property_type} ç¸½åƒ¹å››åˆ†ä½è·: {[f'{x/10000:.0f}è¬' for x in price_stats]}")
    log_to_gcs('INFO', f"{city_name} {property_type} åªæ•¸å››åˆ†ä½è·: {[f'{x:.1f}åª' for x in size_stats]}")
    
    # å»ºç«‹åœ–è¡¨
    fig, ax = plt.subplots(figsize=FIGURE_SIZE_MAP, dpi=80)
    
    # è¨­å®šé¡¯ç¤ºç¯„åœ
    x_margin = (df_city['x'].max() - df_city['x'].min()) * 0.1
    y_margin = (df_city['y'].max() - df_city['y'].min()) * 0.1
    
    ax.set_xlim(df_city['x'].min() - x_margin, df_city['x'].max() + x_margin)
    ax.set_ylim(df_city['y'].min() - y_margin, df_city['y'].max() + y_margin)
    
    # åŠ å…¥åœ°åœ–åº•åœ–
    log_to_gcs('INFO', f"æ­£åœ¨è¼‰å…¥ {city_name} åœ°åœ–åº•åœ–...")
    try:
        cx.add_basemap(
            ax,
            crs='EPSG:3857',
            source=cx.providers.OpenStreetMap.Mapnik,
            zoom='auto',
            alpha=0.85,
            zorder=1
        )
        log_to_gcs('INFO', "åœ°åœ–åº•åœ–è¼‰å…¥æˆåŠŸ")
    except Exception as e:
        log_to_gcs('WARNING', f"åœ°åœ–åº•åœ–è¼‰å…¥å¤±æ•—: {str(e)}")
    
    # ç¹ªè£½æ•£é»åœ–ï¼ˆå¾é«˜åƒ¹åˆ°ä½åƒ¹ï¼Œè®“ä½åƒ¹åœ¨æœ€ä¸Šå±¤ï¼‰
    for price_order in [4, 3, 2, 1]:  # åå‘ç¹ªè£½ï¼Œè®“ä½åƒ¹ï¼ˆæ·±è‰²å°é»ï¼‰åœ¨ä¸Šå±¤
        df_subset = df_city[df_city['price_order'] == price_order]
        
        if len(df_subset) > 0:
            # å–å¾—è©²åˆ†é¡çš„é¡è‰²å’Œå¤§å°
            colors = [PRICE_COLORS[price_order]] * len(df_subset)
            sizes = df_subset['size_order'].map(SIZE_MAPPING).fillna(100)
            
            # å–å¾—åˆ†é¡æ¨™ç±¤
            category_label = df_subset['price_category'].iloc[0]
            
            ax.scatter(
                df_subset['x'],
                df_subset['y'],
                c=colors,
                s=sizes,
                alpha=0.5,
                edgecolors='white',
                linewidth=1,
                zorder=2 + (5 - price_order),  # ä½åƒ¹ zorder æ›´é«˜
                label=f'{category_label} ({len(df_subset)}ç­†)'
            )
    
    # è¨­å®šä¸»æ¨™é¡Œ
    ax.set_title(
        f'{city_name} {property_type} åˆ†å¸ƒåœ–(ä¾ç¸½åƒ¹èˆ‡åªæ•¸å››åˆ†ä½è·åˆ†é¡)',fontsize=22,fontweight='bold',pad=30
    )
    
    # æ·»åŠ è³‡æ–™ç­†æ•¸èªªæ˜ï¼ˆå‰¯æ¨™é¡Œä½ç½®ï¼‰
    if is_sampled:
        subtitle_text = f'ç¹ªåœ–é™åˆ¶ï¼Œå¾ {original_data_count:,} ç­†æ•¸æ“šä¸­éš¨æ©Ÿæ¡æ¨£ {MAX_POINTS:,} ç­†è£½åœ–'
    else:
        subtitle_text = f'è³‡æ–™ç­†æ•¸: {len(df_city):,}'
    
    # åœ¨æ¨™é¡Œä¸‹æ–¹æ·»åŠ å‰¯æ¨™é¡Œ
    ax.text(0.5, 1.01, subtitle_text,ha='center', va='bottom', transform=ax.transAxes,fontsize=11, color='#333333',linespacing=1.5)
    
    # å‰µå»ºåœ–ä¾‹ - ç¸½åƒ¹ï¼ˆå››åˆ†ä½è·ï¼Œå¾ä½åˆ°é«˜æ’åˆ—ï¼‰
    price_categories = df_city[df_city['price_order'] > 0].sort_values('price_order')['price_category'].unique()
    price_legend_elements = [
        Patch(facecolor=PRICE_COLORS[i+1], edgecolor='white',
              label=cat, alpha=0.75)
        for i, cat in enumerate(price_categories)
    ]
    
    legend1 = ax.legend(
        handles=price_legend_elements,
        title='ç¸½åƒ¹å€é–“(å››åˆ†ä½è·)\næ·±è‰²=ä½åƒ¹ï¼Œæ·ºè‰²=é«˜åƒ¹',
        loc='upper left',
        fontsize=10,
        title_fontsize=10,
        framealpha=0.95,
        edgecolor='black'
    )
    ax.add_artist(legend1)
    
    # å‰µå»ºåœ–ä¾‹ - åªæ•¸ï¼ˆå››åˆ†ä½è·ï¼‰
    size_categories = df_city[df_city['size_order'] > 0].sort_values('size_order')['size_category'].unique()
    size_legend_elements = [
        ax.scatter([], [], s=SIZE_MAPPING[i+1], c='#808080',
                  alpha=0.75, edgecolors='white', linewidth=1,
                  label=cat)
        for i, cat in enumerate(size_categories)
    ]
    
    legend2 = ax.legend(
        handles=size_legend_elements,
        title='æˆ¿å±‹åªæ•¸(å››åˆ†ä½è·)',
        loc='upper right',
        fontsize=10,
        title_fontsize=11,
        framealpha=0.95,
        edgecolor='black'
    )
    
    # ç§»é™¤åº§æ¨™è»¸åˆ»åº¦
    ax.set_xticks([])
    ax.set_yticks([])
    ax.set_xlabel('')
    ax.set_ylabel('')
    
    # èª¿æ•´ä½ˆå±€
    plt.tight_layout()
    
    # å„²å­˜åœ–ç‰‡
    buffer = BytesIO()
    plt.savefig(buffer, format='png', dpi=80, bbox_inches='tight', facecolor='white')
    plt.close()
    
    log_to_gcs('INFO', f"{city_name} {property_type} æ•£é»åœ–å·²å®Œæˆ" + (f" (æ¡æ¨£: {original_data_count:,} -> {MAX_POINTS:,})" if is_sampled else ""))
    
    return buffer

def create_heat_maps(**context):
    """ç”Ÿæˆå„ç¸£å¸‚å€åŸŸç†±åº¦åœ°åœ–"""
    log_to_gcs('INFO', "é–‹å§‹ç”Ÿæˆå€åŸŸç†±åº¦åœ°åœ–...")
    
    ti = context['task_instance']
    
    df_used_json = ti.xcom_pull(task_ids='load_data', key='df_used')
    df_new_json = ti.xcom_pull(task_ids='load_data', key='df_new')
    year = ti.xcom_pull(task_ids='load_data', key='year')
    season = ti.xcom_pull(task_ids='load_data', key='season')
    
    df_used = pd.read_json(StringIO(df_used_json), orient='split')
    df_new = pd.read_json(StringIO(df_new_json), orient='split')
    
    # ç¢ºä¿æœ‰ç¶“ç·¯åº¦è³‡æ–™
    if not df_used.empty:
        df_used = df_used.dropna(subset=['latitude', 'longitude'])
    if not df_new.empty:
        df_new = df_new.dropna(subset=['latitude', 'longitude'])
    
    log_to_gcs('INFO', f"ä¸­å¤å±‹æœ‰æ•ˆåº§æ¨™è³‡æ–™: {len(df_used)} ç­†")
    log_to_gcs('INFO', f"æ–°æˆå±‹æœ‰æ•ˆåº§æ¨™è³‡æ–™: {len(df_new)} ç­†")
    
    # æª¢æŸ¥åœ–è¡¨æ˜¯å¦å·²å­˜åœ¨
    check_result = check_charts_exist(year, season)
    
    # æª¢æŸ¥æ˜¯å¦æ‰€æœ‰ç†±åº¦åœ°åœ–éƒ½å­˜åœ¨
    required_heatmap_charts = []
    for display_name, _ in REPORT_CITIES:
        code = CITY_DISPLAY_TO_CODE[display_name]
        required_heatmap_charts.append(f"heatmap_{code}_used")
        required_heatmap_charts.append(f"heatmap_{code}_presale")
    
    all_heatmaps_exist = all(chart in check_result['charts'] for chart in required_heatmap_charts)
    
    if all_heatmaps_exist:
        log_to_gcs('INFO', "æ‰€æœ‰ç†±åº¦åœ°åœ–å·²å­˜åœ¨ï¼Œç›´æ¥è¼‰å…¥")
        heat_map_urls = []
        from utils import get_chart_url_from_gcs
        
        for display_name, _ in REPORT_CITIES:
            code = CITY_DISPLAY_TO_CODE[display_name]
            for map_type in ['used', 'presale']:
                chart_name = f"heatmap_{code}_{map_type}"
                try:
                    url = get_chart_url_from_gcs(year, season, chart_name)
                    heat_map_urls.append({
                        'city': display_name,
                        'type': 'ä¸­å¤å±‹' if map_type == 'used' else 'æ–°æˆå±‹',
                        'url': url
                    })
                except FileNotFoundError:
                    log_to_gcs('WARNING', f"æ‰¾ä¸åˆ° {display_name} {map_type} çš„ç†±åº¦åœ°åœ–")
        
        ti.xcom_push(key='heat_map_urls', value=heat_map_urls)
        return heat_map_urls
    
    # ç”Ÿæˆæ–°åœ–è¡¨
    heat_map_urls = []
    
    for display_name, city_name in REPORT_CITIES:
        # ä¸­å¤å±‹åœ°åœ–
        city_df_used = df_used[df_used['city'] == city_name].copy() if not df_used.empty else pd.DataFrame()
        if len(city_df_used) > 0:
            buffer = create_city_scatter_map(city_df_used, display_name, 'ä¸­å¤å±‹', year, season)
            if buffer:
                # ä¿®æ­£ï¼šbuffer å·²ç¶“åŒ…å«åœ–ç‰‡è³‡æ–™ï¼Œç›´æ¥ä¸Šå‚³
                chart_url = upload_chart_to_gcs(
                    buffer, 
                    f'heatmap_{CITY_DISPLAY_TO_CODE[display_name]}_used', 
                    year, 
                    season, 
                    compress=False
                )
                heat_map_urls.append({
                    'city': display_name,
                    'type': 'ä¸­å¤å±‹',
                    'url': chart_url
                })
        
        # æ–°æˆå±‹åœ°åœ–
        city_df_new = df_new[df_new['city'] == city_name].copy() if not df_new.empty else pd.DataFrame()
        if len(city_df_new) > 0:
            buffer = create_city_scatter_map(city_df_new, display_name, 'æ–°æˆå±‹', year, season)
            if buffer:
                # ä¿®æ­£ï¼šbuffer å·²ç¶“åŒ…å«åœ–ç‰‡è³‡æ–™ï¼Œç›´æ¥ä¸Šå‚³
                chart_url = upload_chart_to_gcs(
                    buffer, 
                    f'heatmap_{CITY_DISPLAY_TO_CODE[display_name]}_presale', 
                    year, 
                    season, 
                    compress=False
                )
                heat_map_urls.append({
                    'city': display_name,
                    'type': 'æ–°æˆå±‹',
                    'url': chart_url
                })
    
    ti.xcom_push(key='heat_map_urls', value=heat_map_urls)
    
    log_to_gcs('INFO', f"æ‰€æœ‰å€åŸŸç†±åº¦åœ°åœ–å·²å®Œæˆï¼Œå…± {len(heat_map_urls)} å¼µ")
    return heat_map_urls

# ==================== Standalone å‡½æ•¸ï¼ˆAPI ä½¿ç”¨ï¼‰====================

def create_stacked_bar_charts_standalone(df_used, df_new, year, season):
    """ç”Ÿæˆå †ç–Šæ©«æ¢åœ–ï¼ˆä¸ä¾è³´ Airflowï¼‰"""
    # æª¢æŸ¥åœ–è¡¨æ˜¯å¦å·²å­˜åœ¨
    check_result = check_charts_exist(year, season)
    
    if check_result['exists']:
        log_to_gcs('INFO', f"åœ–è¡¨å·²å­˜åœ¨ï¼Œç›´æ¥è¼‰å…¥: {check_result['folder']}")
        chart_urls = {}
        for chart_type in ['total_price', 'building_area', 'building_type', 'building_age']:
            chart_name = f"{chart_type}_stacked"
            if chart_name in check_result['charts']:
                from utils import get_chart_url_from_gcs
                chart_urls[chart_type] = get_chart_url_from_gcs(year, season, chart_name)
        return chart_urls
    
    # ç”Ÿæˆæ–°åœ–è¡¨
    chart_urls = {}
    
    if not df_used.empty and not df_new.empty:
        chart_urls['total_price'] = _plot_total_price_distribution(df_used, df_new, year, season)
        chart_urls['building_area'] = _plot_building_area_distribution(df_used, df_new, year, season)
        chart_urls['building_type'] = _plot_building_type_distribution(df_used, df_new, year, season)
    
    if not df_used.empty:
        chart_urls['building_age'] = _plot_building_age_distribution(df_used, year, season)
    
    return chart_urls


def create_summary_section_standalone(df_used, df_new, year, season):
    """ç”Ÿæˆçµ±è¨ˆæ‘˜è¦ï¼ˆä¸ä¾è³´ Airflowï¼‰"""
    # æª¢æŸ¥åœ–è¡¨æ˜¯å¦å·²å­˜åœ¨
    check_result = check_charts_exist(year, season)
    chart_name = 'transaction_count_stacked'
    
    if chart_name in check_result['charts']:
        log_to_gcs('INFO', f"æˆäº¤ä»¶æ•¸åœ–å·²å­˜åœ¨ï¼Œç›´æ¥è¼‰å…¥")
        from utils import get_chart_url_from_gcs
        transaction_count_url = get_chart_url_from_gcs(year, season, chart_name)
    else:
        transaction_count_url = _generate_transaction_count_chart(df_used, df_new, year, season)
    
    # ç”Ÿæˆçµ±è¨ˆè¡¨æ ¼ HTML
    summary_data = []
    
    if not df_used.empty and 'city_display' in df_used.columns:
        for city in df_used['city_display'].unique():
            city_data = df_used[df_used['city_display'] == city]
            summary_data.append({
                'city': city,
                'type': 'ä¸­å¤å±‹',
                'count': len(city_data),
                'avg_total_price': city_data['total_price'].mean() / 10000 if 'total_price' in city_data.columns else 0
            })
    
    if not df_new.empty and 'city_display' in df_new.columns:
        for city in df_new['city_display'].unique():
            city_data = df_new[df_new['city_display'] == city]
            summary_data.append({
                'city': city,
                'type': 'æ–°æˆå±‹',
                'count': len(city_data),
                'avg_total_price': city_data['total_price'].mean() / 10000 if 'total_price' in city_data.columns else 0
            })
    
    summary_df = pd.DataFrame(summary_data)
    
    html = '<table style="width: 100%; border-collapse: collapse; margin: 20px 0; font-size: 14px;">'
    html += '<thead><tr style="background-color: #F3F4F6;">'
    html += '<th style="border: 1px solid #D1D5DB; padding: 8px; color: #000000;">ç¸£å¸‚</th>'
    html += '<th style="border: 1px solid #D1D5DB; padding: 8px; color: #000000;">é¡å‹</th>'
    html += '<th style="border: 1px solid #D1D5DB; padding: 8px; color: #000000;">æˆäº¤ä»¶æ•¸</th>'
    html += '<th style="border: 1px solid #D1D5DB; padding: 8px; color: #000000;">å¹³å‡ç¸½åƒ¹(è¬)</th>'
    html += '</tr></thead><tbody>'
    
    for _, row in summary_df.iterrows():
        html += f'<tr><td style="border: 1px solid #D1D5DB; padding: 8px; color: #000000;">{row["city"]}</td>'
        html += f'<td style="border: 1px solid #D1D5DB; padding: 8px; color: #000000;">{row["type"]}</td>'
        html += f'<td style="border: 1px solid #D1D5DB; padding: 8px; text-align: right; color: #000000;">{row["count"]:,}</td>'
        html += f'<td style="border: 1px solid #D1D5DB; padding: 8px; text-align: right; color: #000000;">{row["avg_total_price"]:.1f}</td></tr>'
    
    html += '</tbody></table>'
    
    return {
        'transaction_count_url': transaction_count_url,
        'table_html': html
    }


def create_city_boxplots_combined_standalone(df_used, df_new, year, season):
    """ç”Ÿæˆç®±å‹åœ–ï¼ˆä¸ä¾è³´ Airflowï¼‰"""
    # æª¢æŸ¥åœ–è¡¨æ˜¯å¦å·²å­˜åœ¨
    check_result = check_charts_exist(year, season)
    required_boxplot_charts = [f"boxplot_{CITY_DISPLAY_TO_CODE[city]}_combined" 
                               for city, _ in REPORT_CITIES]
    all_boxplots_exist = all(chart in check_result['charts'] for chart in required_boxplot_charts)
    
    if all_boxplots_exist:
        log_to_gcs('INFO', "æ‰€æœ‰ç®±å‹åœ–å·²å­˜åœ¨ï¼Œç›´æ¥è¼‰å…¥")
        boxplot_urls = []
        from utils import get_chart_url_from_gcs
        
        for display_name, _ in REPORT_CITIES:
            chart_name = f"boxplot_{CITY_DISPLAY_TO_CODE[display_name]}_combined"
            url = get_chart_url_from_gcs(year, season, chart_name)
            boxplot_urls.append({
                'city': display_name,
                'url': url
            })
        return boxplot_urls
    
    # ç”Ÿæˆæ–°åœ–è¡¨
    city_groups = {}
    
    for display_name, city_name in REPORT_CITIES:
        zones_used = df_used.loc[df_used['city'] == city_name, 'zip_zone'].unique().tolist() if not df_used.empty else []
        zones_new = df_new.loc[df_new['city'] == city_name, 'zip_zone'].unique().tolist() if not df_new.empty else []
        city_groups[display_name] = list(set(zones_used + zones_new))
    
    boxplot_urls = []
    
    for city_name, zones in city_groups.items():
        city_df_used = df_used[df_used['zip_zone'].isin(zones)].copy() if not df_used.empty else pd.DataFrame()
        city_df_new = df_new[df_new['zip_zone'].isin(zones)].copy() if not df_new.empty else pd.DataFrame()
        
        if len(city_df_used) == 0 and len(city_df_new) == 0:
            log_to_gcs('INFO', f"{city_name} ç„¡è³‡æ–™ï¼Œè·³é")
            continue
        
        zone_counts_used = city_df_used['zip_zone'].value_counts() if not city_df_used.empty else pd.Series()
        zone_counts_new = city_df_new['zip_zone'].value_counts() if not city_df_new.empty else pd.Series()
        
        sorted_zones = sorted(zones, 
                            key=lambda x: (zone_counts_new.get(x, 0), zone_counts_used.get(x, 0)), 
                            reverse=True)
        
        # ç¹ªåœ–é‚è¼¯
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=FIGURE_SIZE_LARGE)
        
        def plot_boxplot(ax, city_df, sorted_zones, zone_counts, title_suffix):
            available_zones = [zone for zone in sorted_zones if zone in zone_counts.index]
            
            if len(available_zones) == 0:
                ax.text(0.5, 0.5, 'ç„¡è³‡æ–™', ha='center', va='center', 
                       fontsize=20, transform=ax.transAxes)
                ax.set_title(f'{city_name}{title_suffix} æˆ¿åƒ¹åˆ†å¸ƒèˆ‡æˆäº¤é‡',
                           fontsize=16, pad=20, weight='bold')
                return
            
            city_df['zip_zone'] = pd.Categorical(city_df['zip_zone'],
                                                 categories=available_zones,
                                                 ordered=True)
            
            positions = range(len(available_zones))
            bp = ax.boxplot(
                [city_df[city_df['zip_zone'] == zone]['total_price'].values
                 for zone in available_zones],
                positions=positions,
                widths=0.6,
                patch_artist=True,
                showfliers=False,
                medianprops=dict(color='red', linewidth=2),
                boxprops=dict(facecolor='lightblue', alpha=0.7),
                whiskerprops=dict(linewidth=1.5),
                capprops=dict(linewidth=1.5)
            )
            
            ax.set_xticks(positions)
            ax.set_xticklabels(available_zones, rotation=45, ha='right')
            
            y_min_current, y_max_current = ax.get_ylim()
            
            all_min_values = []
            for zone in available_zones:
                zone_data = city_df[city_df['zip_zone'] == zone]['total_price'].values
                if len(zone_data) > 0:
                    all_min_values.append(zone_data.min())
            
            if all_min_values:
                global_min = min(all_min_values)
                y_range = y_max_current - y_min_current
                label_space = y_range * 0.08
                new_y_min = min(global_min - label_space, y_min_current)
                ax.set_ylim(new_y_min, y_max_current)
                
                for i, zone in enumerate(available_zones):
                    count = zone_counts[zone]
                    zone_data = city_df[city_df['zip_zone'] == zone]['total_price'].values
                    if len(zone_data) > 0:
                        zone_min = zone_data.min()
                        y_pos = (zone_min + new_y_min) / 2
                        
                        ax.text(i, y_pos, f'n={count}',
                               ha='center', va='center', fontsize=9,
                               bbox=dict(boxstyle='round,pad=0.3',
                                       facecolor='yellow', alpha=0.5))
            
            ax.yaxis.set_major_formatter(
                plt.FuncFormatter(lambda x, p: f'{int(x/10000)}è¬'))
            
            ax.set_xlabel('å€åŸŸ', fontsize=12, weight='bold')
            ax.set_ylabel('ç¸½åƒ¹ (è¬å…ƒ)', fontsize=12, weight='bold')
            ax.set_title(f'{city_name}{title_suffix} æˆ¿åƒ¹åˆ†å¸ƒèˆ‡æˆäº¤é‡',
                        fontsize=16, pad=20, weight='bold')
            
            ax.grid(axis='y', alpha=0.3, linestyle='--')
            
            total_transactions = len(city_df[city_df['zip_zone'].isin(available_zones)])
            median_price = city_df[city_df['zip_zone'].isin(available_zones)]['total_price'].median()
            mean_price = city_df[city_df['zip_zone'].isin(available_zones)]['total_price'].mean()
            
            stats_text = (f'ç¸½æˆäº¤æ•¸: {total_transactions:,}ç­†\n'
                         f'ä¸­ä½æ•¸: {median_price/10000:.0f}è¬\n'
                         f'å¹³å‡æ•¸: {mean_price/10000:.0f}è¬')
            
            ax.text(0.02, 0.98, stats_text, transform=ax.transAxes,
                   fontsize=10, verticalalignment='top',
                   bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
        
        plot_boxplot(ax1, city_df_used, sorted_zones, zone_counts_used, 'ä¸­å¤å±‹')
        plot_boxplot(ax2, city_df_new, sorted_zones, zone_counts_new, 'æ–°æˆå±‹')
        
        plt.tight_layout()
        
        # å„²å­˜ä¸¦ä¸Šå‚³
        buffer = BytesIO()
        plt.savefig(buffer, format='png', dpi=CHART_DPI, bbox_inches='tight')
        plt.close()
        
        chart_url = upload_chart_to_gcs(
            buffer, 
            f'boxplot_{CITY_DISPLAY_TO_CODE[city_name]}_combined', 
            year, 
            season, 
            compress=False
        )
        boxplot_urls.append({
            'city': city_name,
            'url': chart_url
        })
        
        log_to_gcs('INFO', f"{city_name} ä¸¦æ’ç®±å‹åœ–å·²å®Œæˆ")
    
    return boxplot_urls


def create_heat_maps_standalone(df_used, df_new, year, season):
    """ç”Ÿæˆç†±åº¦åœ°åœ–ï¼ˆä¸ä¾è³´ Airflowï¼‰"""
    # æª¢æŸ¥åœ–è¡¨æ˜¯å¦å·²å­˜åœ¨
    check_result = check_charts_exist(year, season)
    required_heatmap_charts = []
    for display_name, _ in REPORT_CITIES:
        code = CITY_DISPLAY_TO_CODE[display_name]
        required_heatmap_charts.append(f"heatmap_{code}_used")
        required_heatmap_charts.append(f"heatmap_{code}_presale")
    
    all_heatmaps_exist = all(chart in check_result['charts'] for chart in required_heatmap_charts)
    
    if all_heatmaps_exist:
        log_to_gcs('INFO', "æ‰€æœ‰ç†±åº¦åœ°åœ–å·²å­˜åœ¨ï¼Œç›´æ¥è¼‰å…¥")
        heat_map_urls = []
        from utils import get_chart_url_from_gcs
        
        for display_name, _ in REPORT_CITIES:
            code = CITY_DISPLAY_TO_CODE[display_name]
            for map_type in ['used', 'presale']:
                chart_name = f"heatmap_{code}_{map_type}"
                try:
                    url = get_chart_url_from_gcs(year, season, chart_name)
                    heat_map_urls.append({
                        'city': display_name,
                        'type': 'ä¸­å¤å±‹' if map_type == 'used' else 'æ–°æˆå±‹',
                        'url': url
                    })
                except FileNotFoundError:
                    log_to_gcs('WARNING', f"æ‰¾ä¸åˆ° {display_name} {map_type} çš„ç†±åº¦åœ°åœ–")
        
        return heat_map_urls
    
    # ç”Ÿæˆæ–°åœ–è¡¨
    heat_map_urls = []
    
    # ç¢ºä¿æœ‰ç¶“ç·¯åº¦è³‡æ–™
    if not df_used.empty:
        df_used = df_used.dropna(subset=['latitude', 'longitude'])
    if not df_new.empty:
        df_new = df_new.dropna(subset=['latitude', 'longitude'])
    
    for display_name, city_name in REPORT_CITIES:
        # ä¸­å¤å±‹åœ°åœ–
        city_df_used = df_used[df_used['city'] == city_name].copy() if not df_used.empty else pd.DataFrame()
        if len(city_df_used) > 0:
            buffer = create_city_scatter_map(city_df_used, display_name, 'ä¸­å¤å±‹', year, season)
            if buffer:
                # ä¿®æ­£
                chart_url = upload_chart_to_gcs(
                    buffer, 
                    f'heatmap_{CITY_DISPLAY_TO_CODE[display_name]}_used', 
                    year, 
                    season, 
                    compress=False
                )
                heat_map_urls.append({
                    'city': display_name,
                    'type': 'ä¸­å¤å±‹',
                    'url': chart_url
                })
        
        # æ–°æˆå±‹åœ°åœ–
        city_df_new = df_new[df_new['city'] == city_name].copy() if not df_new.empty else pd.DataFrame()
        if len(city_df_new) > 0:
            buffer = create_city_scatter_map(city_df_new, display_name, 'æ–°æˆå±‹', year, season)
            if buffer:
                # ä¿®æ­£
                chart_url = upload_chart_to_gcs(
                    buffer, 
                    f'heatmap_{CITY_DISPLAY_TO_CODE[display_name]}_presale', 
                    year, 
                    season, 
                    compress=False
                )
                heat_map_urls.append({
                    'city': display_name,
                    'type': 'æ–°æˆå±‹',
                    'url': chart_url
                })
    
    return heat_map_urls